// Module included in the following assemblies:
//
// * documentation/doc-Migration_Toolkit_for_Virtualization/master.adoc

[id="migrating-virtual-machines-cli_{context}"]
= Migrating virtual machines from the CLI

You can migrate virtual machines (VMs) from the command line (CLI) by creating the following custom resources (CRs):

* `Secret` CR contains the VMware provider credentials.
* `Provider` CR describes the VMware provider.
* `Plan` CR describes the source and target clusters, network mappings, data store mappings, and VMs to migrate.
* `Migration` CR runs the `Plan` CR.
+
You can associate multiple `Migration` CRs with a single `Plan` CR. If a migration does not complete, you can create a new `Migration` CR, without changing the `Plan` CR, to migrate the remaining VMs.

.Prerequisites

* The link:https://docs.openshift.com/container-platform/{ocp-version}/cli_reference/openshift_cli/getting-started-cli.html[OpenShift CLI] must be installed.
* The VDDK image must be added to the `v2v-vmware` config map.
* For warm migration, you must enable link:https://kb.vmware.com/s/article/1020128[changed block tracking (CBT)] on the VMs and on the VM disks.

.Procedure

. Obtain the SHA-1 fingerprint of the vCenter host:
+
[source,terminal]
----
$ openssl s_client \
    -connect <vcenter_host>:443 \ <1>
    < /dev/null 2>/dev/null \
    | openssl x509 -fingerprint -noout -in /dev/stdin \
    | cut -d '=' -f 2
----
<1> Specify the vCenter host name.
+
.Example output
+
[source,terminal]
----
01:23:45:67:89:AB:CD:EF:01:23:45:67:89:AB:CD:EF:01:23:45:67
----

. Create a `Secret` CR manifest for the VMware provider:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | oc apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: vmware-secret
  namespace: {namespace}
type: Opaque
stringData:
  user: <user_name> <1>
  password: <password> <2>
  thumbprint: <fingerprint> <3>
EOF
----
<1> Specify the vCenter administrator account, for example, `administrator@vsphere.local`.
<2> Specify the vCenter password.
<3> Specify the SHA-1 fingerprint of the vCenter host.

. Create a `Provider` CR manifest for the VMware provider:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | oc apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Provider
metadata:
  name: vmware-provider
  namespace: {namespace}
spec:
  type: vsphere
  url: <api_end_point> <1>
  secret:
    name: <vmware_secret> <2>
    namespace: {namespace}
EOF
----
<1> Specify the vSphere API end point, for example, `https://<vcenter.host.com>/sdk`.
<2> Specify the name of the VMware `Secret` CR.

. Create a `Host` CR manifest for the VMware host:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | oc apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Host
metadata:
  name: vmware_host
  namespace: {namespace}
spec:
  provider:
    namespace: {namespace}
    name: <provider_name> <1>
  id: <source_host_mor> <2>
  ipAddress: <source_network> <3>
EOF
----
<1> Specify the name of the VMware `Provider` CR.
<2> Specify the _managed object reference_ of the VMware host.
<3> Specify the IP address of the VMware migration network.

. Create a `Plan` CR manifest for the migration:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | oc apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Plan
metadata:
  name: <plan_name> <1>
  namespace: {namespace}
spec:
  provider:
    source:
      name: vmware-provider
      namespace: {namespace}
    destination:
      name: destination-cluster
      namespace: {namespace}
  warm: true <2>
  map:
    networks: <3>
      - source: <4>
          id: <source_network_mor> <5>
          name: <source_network_name>
        destination:
          type: pod
          name: pod
          namespace: {namespace}
    datastores: <6>
      - source: <7>
          id: <source_datastore_mor> <8>
          name: <source_datastore_name>
        destination:
          storageClass: standard
  vms: <9>
    - id: <source_vm_mor> <10>
    - name: <source_vm_name>
EOF
----
<1> Specify the name of the `Plan` CR.
<2> Specify whether the migration is warm or cold. If you specify a warm migration without specifying a `cutover` time, only the `precopy` runs.
<3> You can create multiple network mappings for source and destination networks.
<4> You can use either the `id` _or_ the `name` parameter to specify the source network.
<5> _Managed object reference_ of the source network.
<6> You can create multiple storage mappings for source data stores and destination storage classes.
<7> You can use either the `id` _or_ the `name` parameter to specify the source data store.
<8> _Managed object reference_ of the source data store.
<9>  You can use either the `id` _or_ the `name` parameter to specify the source VM.
<10> _Managed object reference_ of the source VM.

. Optional. To change the time interval between the CBT snapshots for warm migration, patch the `vm-import-controller-config` config map:
+
[source,terminal,subs="attributes+"]
----
$ oc patch configmap/vm-import-controller-config -n openshift-cnv \
  -p '{"data": {"warmImport.intervalMinutes": "<interval>"}}' <1>
----
<1> Specify the time interval in minutes. The default value is `60`.

. Create a `Migration` CR manifest to run the `Plan` CR:
+
[source,yaml,subs="attributes+"]
----
$ cat << EOF | oc apply -f -
apiVersion: forklift.konveyor.io/v1beta1
kind: Migration
metadata:
  name: <migration_name> <1>
  namespace: {namespace}
spec:
  plan:
    name: <plan_name> <2>
    namespace: {namespace}
  cutover: <cutover_time> <3>
EOF
----
<1> Specify the name of the `Migration` CR.
<2> Specify the name of the `Plan` CR that you are running. The `Migration` CR creates a `VirtualMachineImport` CR for each VM that is migrated.
<3> Optional. Specify a cutover time according to the ISO 8601 format with the UTC time offset, for example, `2021-04-04T01:23:45.678+09:00`.

. View the `VirtualMachineImport` pods to monitor the progress of the migration:
+
[source,terminal,subs="attributes+"]
----
$ oc get pods -n {namespace}
----
